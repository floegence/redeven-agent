package ai

import (
	"context"
	"fmt"
	"io"
	"log/slog"
	"net/http"
	"net/http/httptest"
	"strings"
	"testing"
	"time"

	"github.com/floegence/redeven-agent/internal/config"
	"github.com/floegence/redeven-agent/internal/session"
)

func newIntentRoutingService(t *testing.T, mock *openAIMock) (*Service, session.Meta) {
	t.Helper()

	srv := httptest.NewServer(http.HandlerFunc(mock.handle))
	t.Cleanup(srv.Close)

	cfg := &config.AIConfig{
		Providers: []config.AIProvider{
			{
				ID:      "openai",
				Name:    "OpenAI",
				Type:    "openai",
				BaseURL: strings.TrimSuffix(srv.URL, "/") + "/v1",
				Models:  []config.AIProviderModel{{ModelName: "gpt-5-mini", IsDefault: true}},
			},
		},
	}

	meta := session.Meta{
		EndpointID:        "env_test",
		NamespacePublicID: "ns_test",
		ChannelID:         "ch_intent_router",
		UserPublicID:      "u_test",
		UserEmail:         "u_test@example.com",
		CanRead:           true,
		CanWrite:          true,
		CanExecute:        true,
		CanAdmin:          true,
	}

	svc, err := NewService(Options{
		Logger:              slog.New(slog.NewTextHandler(io.Discard, &slog.HandlerOptions{Level: slog.LevelInfo})),
		StateDir:            t.TempDir(),
		FSRoot:              t.TempDir(),
		Shell:               "bash",
		Config:              cfg,
		RunMaxWallTime:      30 * time.Second,
		RunIdleTimeout:      10 * time.Second,
		ToolApprovalTimeout: 5 * time.Second,
		ResolveProviderAPIKey: func(providerID string) (string, bool, error) {
			if strings.TrimSpace(providerID) != "openai" {
				return "", false, nil
			}
			return "sk-test", true, nil
		},
	})
	if err != nil {
		t.Fatalf("NewService: %v", err)
	}
	t.Cleanup(func() { _ = svc.Close() })

	return svc, meta
}

func findRunEventPayload(t *testing.T, events []RunEventView, eventType string) map[string]any {
	t.Helper()
	for _, ev := range events {
		if strings.TrimSpace(ev.EventType) != strings.TrimSpace(eventType) {
			continue
		}
		payload, ok := ev.Payload.(map[string]any)
		if !ok {
			t.Fatalf("event %q payload type=%T, want map[string]any", eventType, ev.Payload)
		}
		return payload
	}
	t.Fatalf("missing run event %q", eventType)
	return nil
}

func TestIntentRouting_SocialInputUsesSocialPathWithoutTools(t *testing.T) {
	t.Parallel()

	mock := &openAIMock{token: "SOCIAL_REPLY_OK"}
	svc, meta := newIntentRoutingService(t, mock)

	ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
	defer cancel()

	thread, err := svc.CreateThread(ctx, &meta, "social test", "")
	if err != nil {
		t.Fatalf("CreateThread: %v", err)
	}

	runID := "run_intent_social_1"
	rr := httptest.NewRecorder()
	err = svc.StartRun(ctx, &meta, runID, RunStartRequest{
		ThreadID: thread.ThreadID,
		Model:    "openai/gpt-5-mini",
		Input:    RunInput{Text: "hello"},
		Options:  RunOptions{MaxSteps: 1, Mode: "plan"},
	}, rr)
	if err != nil {
		t.Fatalf("StartRun: %v", err)
	}

	if !strings.Contains(rr.Body.String(), "SOCIAL_REPLY_OK") {
		t.Fatalf("stream output missing social reply token, body=%q", rr.Body.String())
	}
	if !mock.didSeeResponses() {
		t.Fatalf("expected OpenAI responses call")
	}
	if names := mock.toolNamesSnapshot(); len(names) != 0 {
		t.Fatalf("social path must not send tools, got=%v", names)
	}

	runEvents, err := svc.ListRunEvents(ctx, &meta, runID, 2000)
	if err != nil {
		t.Fatalf("ListRunEvents: %v", err)
	}
	classified := findRunEventPayload(t, runEvents.Events, "intent.classified")
	if got := strings.TrimSpace(fmt.Sprint(classified["intent"])); got != RunIntentSocial {
		t.Fatalf("intent=%q, want %q", got, RunIntentSocial)
	}
	routed := findRunEventPayload(t, runEvents.Events, "intent.routed")
	if got := strings.TrimSpace(fmt.Sprint(routed["path"])); got != "social_responder" {
		t.Fatalf("intent path=%q, want social_responder", got)
	}
}

func TestIntentRouting_ContinuationWithOpenGoalStaysTask(t *testing.T) {
	t.Parallel()

	mock := &openAIMock{token: "TASK_REPLY_OK"}
	svc, meta := newIntentRoutingService(t, mock)

	ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
	defer cancel()

	thread, err := svc.CreateThread(ctx, &meta, "task test", "")
	if err != nil {
		t.Fatalf("CreateThread: %v", err)
	}

	firstRunID := "run_intent_task_seed_1"
	firstRR := httptest.NewRecorder()
	err = svc.StartRun(ctx, &meta, firstRunID, RunStartRequest{
		ThreadID: thread.ThreadID,
		Model:    "openai/gpt-5-mini",
		Input:    RunInput{Text: "Please analyze this repository structure."},
		Options:  RunOptions{MaxSteps: 1, MaxNoToolRounds: 1, Mode: "plan"},
	}, firstRR)
	if err != nil {
		t.Fatalf("StartRun seed task: %v", err)
	}

	secondRunID := "run_intent_task_continue_1"
	secondRR := httptest.NewRecorder()
	err = svc.StartRun(ctx, &meta, secondRunID, RunStartRequest{
		ThreadID: thread.ThreadID,
		Model:    "openai/gpt-5-mini",
		Input:    RunInput{Text: "continue"},
		Options:  RunOptions{MaxSteps: 1, MaxNoToolRounds: 1, Mode: "plan"},
	}, secondRR)
	if err != nil {
		t.Fatalf("StartRun continuation: %v", err)
	}

	if !strings.Contains(secondRR.Body.String(), "TASK_REPLY_OK") {
		t.Fatalf("stream output missing continuation reply token, body=%q", secondRR.Body.String())
	}
	if names := mock.toolNamesSnapshot(); len(names) == 0 {
		t.Fatalf("task path should include tools, got none")
	}

	runEvents, err := svc.ListRunEvents(ctx, &meta, secondRunID, 2000)
	if err != nil {
		t.Fatalf("ListRunEvents: %v", err)
	}
	classified := findRunEventPayload(t, runEvents.Events, "intent.classified")
	if got := strings.TrimSpace(fmt.Sprint(classified["intent"])); got != RunIntentTask {
		t.Fatalf("intent=%q, want %q", got, RunIntentTask)
	}
	if got := strings.TrimSpace(fmt.Sprint(classified["reason"])); got != "thread_has_open_goal_and_user_requests_continuation" {
		t.Fatalf("reason=%q, want thread_has_open_goal_and_user_requests_continuation", got)
	}
	routed := findRunEventPayload(t, runEvents.Events, "intent.routed")
	if got := strings.TrimSpace(fmt.Sprint(routed["path"])); got != "task_engine" {
		t.Fatalf("intent path=%q, want task_engine", got)
	}
}
